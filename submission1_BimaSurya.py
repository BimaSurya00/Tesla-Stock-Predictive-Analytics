# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17J_LDBWaygAek1TobA0DFySnAI66c3zG

# Nama  : Bima Surya Nurwahid
# NIM   : m183x0325
# Kelas : M06
# Univ  : Universitas Amikom Yogyakarta

# Import Libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np

from matplotlib import pyplot as plt
import seaborn as sns
# %matplotlib inline

from sklearn.decomposition import PCA
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score
from sklearn.metrics import mean_squared_error
from sklearn.impute import SimpleImputer

from sklearn.svm import SVR
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.neighbors import KNeighborsRegressor

"""# collecting Dataset"""

!pip install -q kaggle

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 /root/.kaggle/kaggle.json

!kaggle datasets download -d rpaguirre/tesla-stock-price

!unzip '/content/tesla-stock-price.zip'

df = pd.read_csv('/content/Tesla.csv - Tesla.csv.csv')
df.head(5)

df.shape

df.info()

"""## Exploratory Data Analysis (EDA)"""

df['Volume'] = df['Volume'].astype(float)

df.info()

df.isnull().sum()

"""# Statistic Dataset Information"""

df.describe()

"""# Data Visulaisation"""

numerical_col = [col for col in df.columns if df[col].dtypes == 'float64']
plt.subplots(figsize=(15,10))
sns.boxplot(data=df[numerical_col]).set_title("Tesla Stock Price")
plt.show()

Q1 = df.quantile(0.25)
Q3 = df.quantile(0.75)
IQR = Q3-Q1
df = df[~((df<(Q1-1.5*IQR))|(df>(Q3+1.5*IQR))).any(axis=1)]

df.shape

numerical_data = [col for col in df.columns if df[col].dtype == 'float64']
plt.figure(figsize=(20, 10))
sns.boxplot(data=df[numerical_data]).set_title('Tesla Stock Price ')
plt.show()

df.shape

"""# Univariate Analysis"""

df.hist(bins=50, figsize=(20,15))
plt.show()

"""# Multivariate Analysis"""

sns.pairplot(df, diag_kind = 'kde')

plt.figure(figsize=(10, 8))
correlation_matrix = df.corr().round(2)
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

Tesla = df.drop(['Date', 'Volume', 'Close'], axis=1)
Tesla.head()

"""# Splitting Data"""

X = Tesla.iloc[:, :-1].values
y = Tesla.iloc[:, -1].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)

print('X_train has', len(X_train), 'records')
print('y_train has', len(y_train), 'records')
print('X_test has', len(X_test), 'records')
print('y_test has', len(y_test), 'records')

"""# Normalization"""

scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

models = pd.DataFrame(columns=['train_mse', 'test_mse'],
                      index=['SVR', 'KNN', 'GradientBoosting'])

"""# Modelling"""

def grid_search(model, hyperparameters):
  results = GridSearchCV(
      model,
      hyperparameters,
      cv=5,
      verbose=1,
      n_jobs=6
  )

  return results

svr = SVR()
hyperparameters = {
    'kernel': ['rbf'],
    'C': [0.001, 0.01, 0.1, 10, 100, 1000],
    'gamma': [0.3, 0.03, 0.003, 0.0003]
}

svr_search = grid_search(svr, hyperparameters)
svr_search.fit(X_train, y_train)
print(svr_search.best_params_)
print(svr_search.best_score_)

knn = KNeighborsRegressor()
hyperparameters = {
    'n_neighbors': range(1, 10)
}

knn_search = grid_search(knn, hyperparameters)
knn_search.fit(X_train, y_train)
print(knn_search.best_params_)
print(knn_search.best_score_)

gradient_boost = GradientBoostingRegressor()
hyperparameters = {
    'learning_rate': [0.01, 0.001, 0.0001],
    'n_estimators': [250, 500, 750, 1000],
    'criterion': ['friedman_mse', 'squared_error']
}

gradient_boost_search = grid_search(gradient_boost, hyperparameters)
gradient_boost_search.fit(X_train, y_train)
print(gradient_boost_search.best_params_)
print(gradient_boost_search.best_score_)

"""# Fitting Model"""

svr = SVR(C=1000, gamma=0.003, kernel='rbf')
svr.fit(X_train, y_train)

knn = KNeighborsRegressor(n_neighbors=6)
knn.fit(X_train, y_train)

gradient_boost = GradientBoostingRegressor(criterion='squared_error',
                                           learning_rate=0.01, n_estimators=1000)
gradient_boost.fit(X_train, y_train)

"""# Model Evaluation"""

model_dict = {
    'SVR': svr,
    'KNN': knn,
    'GradientBoosting': gradient_boost,
    
}

for name, model in model_dict.items():
  models.loc[name, 'train_mse'] = mean_squared_error(y_train, model.predict(X_train))
  models.loc[name, 'test_mse'] = mean_squared_error(y_test, model.predict(X_test))

models.head()

models.sort_values(by='test_mse', ascending=False).plot(kind='bar', zorder=3)

svr_acc = svr.score(X_test, y_test)*100
knn_acc = knn.score(X_test, y_test)*100
boosting_acc = gradient_boost.score(X_test, y_test)*100

evaluation_list = [[svr_acc], [knn_acc], [boosting_acc]]
evaluation = pd.DataFrame(evaluation_list,
                          columns = ['Accuracy (%)'],
                          index = ['SVR', 'KNN', 'Gradient Boost'])

evaluation

"""# Forecasting Price"""

X_30=X[-30:]
forecast=knn.predict(X_30)

forecast=pd.DataFrame(forecast,columns=['Forecast'])
Tesla = Tesla.append(forecast)
Tesla.drop(['High', 'Low', 'Open'],axis=1,inplace=True)

Tesla.tail(35)

